# Prior Art Search System ğŸ”

A comprehensive NLP-based system for automated prior art search and novelty assessment in patent applications.

## ğŸ“‹ Overview

This system provides an end-to-end pipeline for:
1. **Text Extraction**: Extract text from PDFs or accept direct input
2. **Preprocessing**: Clean and normalize text using spaCy
3. **Summarization**: Generate concise summaries using TextRank
4. **Keyword Extraction**: Extract relevant keywords using YAKE, RAKE, and KeyBERT
5. **Similarity Analysis**: Compare inventions with prior art using TF-IDF and BERT
6. **Citation Ranking**: Rank prior art by relevance
7. **Novelty Assessment**: Compute novelty scores

## ğŸ—ï¸ Project Structure

```
prior_art_search/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py          # Text cleaning and preprocessing
â”‚   â”œâ”€â”€ pdf_extractor.py          # PDF text extraction
â”‚   â”œâ”€â”€ summarization.py          # Text summarization
â”‚   â”œâ”€â”€ keyword_extraction.py     # Keyword extraction (YAKE, RAKE, KeyBERT)
â”‚   â”œâ”€â”€ similarity_ranking.py     # Similarity computation and ranking
â”‚   â”œâ”€â”€ pipeline.py               # Main pipeline integrating all components
â”‚   â””â”€â”€ web_interface.py          # Flask web interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/                    # Input files directory
â”‚   â””â”€â”€ output/                   # Output results directory
â”œâ”€â”€ notebooks/                    # Jupyter notebooks for experimentation
â”œâ”€â”€ tests/                        # Unit tests
â””â”€â”€ requirements.txt              # Python dependencies
```

## ğŸš€ Installation

### Step 1: Clone or Download the Project

```bash
cd prior_art_search
```

### Step 2: Create a Virtual Environment (Recommended)

```bash
# Create virtual environment
python -m venv venv

# Activate it
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Download spaCy Language Model

```bash
python -m spacy download en_core_web_sm
```

### Optional: Install sumy for Better Summarization

```bash
pip install sumy
```

## ğŸ“– Usage

### Option 1: Command Line (Python Script)

```python
from src.pipeline import PriorArtPipeline

# Initialize pipeline
pipeline = PriorArtPipeline(output_dir="data/output")

# Your invention description
invention = """
A novel machine learning system for real-time emotion detection
using multimodal deep learning combining facial expressions and
voice patterns...
"""

# Prior art documents
prior_art = [
    {
        'text': 'Facial recognition system using CNNs...',
        'metadata': {'id': 'P001', 'year': 2020}
    },
    # Add more documents...
]

# Run analysis
results = pipeline.run_full_pipeline(
    invention_input=invention,
    prior_art_docs=prior_art,
    is_file=False,
    similarity_method="hybrid",
    save_results=True
)

# Print results
pipeline.print_results(results)
```

### Option 2: Web Interface

```bash
cd src
python web_interface.py
```

Then open your browser to `http://localhost:5000`

### Option 3: Individual Modules

#### Preprocessing
```python
from src.preprocessing import TextPreprocessor

preprocessor = TextPreprocessor()
cleaned = preprocessor.preprocess(text)
```

#### Keyword Extraction
```python
from src.keyword_extraction import KeywordExtractor

extractor = KeywordExtractor()
keywords = extractor.extract_with_yake(text, top_n=10)
```

#### Similarity Analysis
```python
from src.similarity_ranking import CitationRanker

ranker = CitationRanker()
ranked = ranker.rank_documents(query, documents, method="hybrid")
```

## ğŸ”§ Module Details

### 1. Preprocessing (`preprocessing.py`)

**Features:**
- Text cleaning (remove URLs, emails, special characters)
- Lemmatization
- Stopword removal
- Noun phrase extraction

**Example:**
```python
preprocessor = TextPreprocessor()
clean_text = preprocessor.clean_text(raw_text)
lemmatized = preprocessor.lemmatize(text, remove_stopwords=True)
```

### 2. PDF Extraction (`pdf_extractor.py`)

**Features:**
- Extract text from PDFs using PyPDF2 or pdfplumber
- Handle both file and direct text input
- Extract metadata

**Example:**
```python
extractor = PDFExtractor()
result = extractor.extract("path/to/file.pdf", method="pdfplumber")
print(result['text'])
```

### 3. Summarization (`summarization.py`)

**Features:**
- TextRank-based extractive summarization
- Fallback to simple sentence extraction
- Configurable summary length

**Example:**
```python
summarizer = ModernTextSummarizer()
summary = summarizer.summarize_with_textrank(text, sentence_count=3)
```

### 4. Keyword Extraction (`keyword_extraction.py`)

**Algorithms:**
- **YAKE**: Statistical + linguistic features
- **RAKE**: Rapid keyword extraction
- **KeyBERT**: BERT-based semantic extraction

**Example:**
```python
extractor = KeywordExtractor()

# Single method
yake_kw = extractor.extract_with_yake(text, top_n=10)

# All methods combined
all_kw = extractor.extract_combined(text, top_n=10)
unique = extractor.get_unique_keywords(all_kw, top_n=15)
```

### 5. Similarity & Ranking (`similarity_ranking.py`)

**Methods:**
- **TF-IDF**: Fast, interpretable, statistical
- **BERT**: Semantic, context-aware
- **Hybrid**: Combines both (recommended)

**Example:**
```python
ranker = CitationRanker()

# Rank documents
ranked = ranker.rank_documents(
    query_text=invention,
    documents=prior_art_list,
    method="hybrid",
    top_n=10
)

# Compute novelty
novelty = ranker.compute_novelty_score(
    query_text=invention,
    prior_art_docs=prior_art_texts,
    method="hybrid"
)
```

### 6. Main Pipeline (`pipeline.py`)

**Complete Workflow:**
```python
pipeline = PriorArtPipeline()

results = pipeline.run_full_pipeline(
    invention_input=text_or_pdf_path,
    prior_art_docs=prior_art_list,
    is_file=False,
    similarity_method="hybrid",
    save_results=True
)
```

## ğŸ“Š Output Format

The pipeline generates a comprehensive JSON report:

```json
{
  "input_metadata": {
    "filename": "invention.txt",
    "num_pages": 1,
    "input_length": 1250
  },
  "analysis": {
    "original_text": "...",
    "cleaned_text": "...",
    "summary": "...",
    "keywords": {
      "yake": [...],
      "rake": [...],
      "unique_keywords": [...]
    }
  },
  "prior_art_comparison": {
    "ranked_citations": [...],
    "novelty_metrics": {
      "novelty_score": 0.72,
      "max_similarity": 0.28,
      "avg_similarity": 0.15
    }
  }
}
```

## ğŸ¯ Use Cases

1. **Patent Filing**: Assess novelty before filing
2. **Prior Art Search**: Find relevant existing patents
3. **R&D**: Identify gaps in existing technology
4. **Legal Analysis**: Support patent litigation
5. **Technology Scouting**: Discover similar innovations

## âš™ï¸ Configuration

### Similarity Methods

- **TF-IDF**: Fastest, good for keyword matching
- **BERT**: Best semantic understanding, slower
- **Hybrid** (recommended): Balance of speed and accuracy

### Keyword Extraction

- **YAKE**: Best for general use, no training needed
- **RAKE**: Fast, good for technical documents
- **KeyBERT**: Most accurate, requires more resources

## ğŸ“ˆ Performance Tips

1. **For faster processing**: Use `tfidf` similarity method
2. **For better accuracy**: Use `hybrid` or `bert` method
3. **Memory optimization**: Avoid loading KeyBERT unless needed
4. **Large corpora**: Process in batches

## ğŸ§ª Testing

Run individual module tests:

```bash
cd src
python preprocessing.py
python keyword_extraction.py
python similarity_ranking.py
python pipeline.py
```

## ğŸ” Example Workflow

```python
# Step 1: Initialize
from src.pipeline import PriorArtPipeline
pipeline = PriorArtPipeline()

# Step 2: Prepare input
invention = "A neural network system for automated patent analysis..."

prior_art = [
    {'text': 'Patent 1 description...', 'metadata': {'id': 'P1'}},
    {'text': 'Patent 2 description...', 'metadata': {'id': 'P2'}},
]

# Step 3: Run analysis
results = pipeline.run_full_pipeline(
    invention_input=invention,
    prior_art_docs=prior_art,
    similarity_method="hybrid"
)

# Step 4: View results
pipeline.print_results(results)

# Step 5: Check novelty
novelty_score = results['prior_art_comparison']['novelty_metrics']['novelty_score']
if novelty_score > 0.7:
    print("HIGH novelty - proceed with patent filing")
elif novelty_score > 0.4:
    print("MODERATE novelty - review similar patents")
else:
    print("LOW novelty - significant prior art exists")
```

## ğŸ“ Notes

- **First Run**: May take longer as models are downloaded
- **GPU**: Not required but speeds up BERT operations
- **Memory**: Minimum 4GB RAM recommended
- **Python**: Version 3.8+ required

## ğŸ¤ Contributing

Feel free to enhance the system by:
- Adding new keyword extraction methods
- Implementing additional similarity metrics
- Improving the web interface
- Adding database integration

## ğŸ“„ License

This project uses various open-source libraries. See individual module licenses.

## ğŸ†˜ Troubleshooting

### Issue: spaCy model not found
```bash
python -m spacy download en_core_web_sm
```

### Issue: KeyBERT slow on CPU
Use TF-IDF method instead or install CUDA support

### Issue: Import errors
Make sure you're in the correct directory and virtual environment is activated

## ğŸ“§ Support

For issues or questions, please refer to the documentation in each module file.

---

**Built with**: spaCy, Gensim, scikit-learn, YAKE, KeyBERT, Sentence-Transformers   


# System Architecture

## Overall Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INPUT LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  PDF File  â”‚              â”‚  Text Input  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EXTRACTION LAYER                           â”‚
â”‚               (pdf_extractor.py)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  â€¢ PyPDF2 / pdfplumber                           â”‚       â”‚
â”‚  â”‚  â€¢ Text extraction                                â”‚       â”‚
â”‚  â”‚  â€¢ Metadata extraction                            â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PREPROCESSING LAYER                          â”‚
â”‚               (preprocessing.py)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  â€¢ Text cleaning (spaCy)                         â”‚       â”‚
â”‚  â”‚  â€¢ Lemmatization                                  â”‚       â”‚
â”‚  â”‚  â€¢ Stopword removal                               â”‚       â”‚
â”‚  â”‚  â€¢ Noun phrase extraction                         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                               â”‚
         â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SUMMARIZATION   â”‚          â”‚    KEYWORD       â”‚
â”‚     LAYER        â”‚          â”‚   EXTRACTION     â”‚
â”‚ (summarization   â”‚          â”‚     LAYER        â”‚
â”‚      .py)        â”‚          â”‚ (keyword_        â”‚
â”‚                  â”‚          â”‚  extraction.py)  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  TextRank  â”‚  â”‚          â”‚  â”‚   YAKE     â”‚  â”‚
â”‚  â”‚   (sumy)   â”‚  â”‚          â”‚  â”‚   RAKE     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚          â”‚  â”‚  KeyBERT   â”‚  â”‚
â”‚                  â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                            â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SIMILARITY & RANKING LAYER                      â”‚
â”‚            (similarity_ranking.py)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                                                    â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚       â”‚
â”‚  â”‚  â”‚  TF-IDF  â”‚  â”‚   BERT   â”‚  â”‚  Hybrid  â”‚       â”‚       â”‚
â”‚  â”‚  â”‚          â”‚  â”‚          â”‚  â”‚          â”‚       â”‚       â”‚
â”‚  â”‚  â”‚ (scikit) â”‚  â”‚(Sentence â”‚  â”‚(Combined)â”‚       â”‚       â”‚
â”‚  â”‚  â”‚          â”‚  â”‚Transform)â”‚  â”‚          â”‚       â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚       â”‚
â”‚  â”‚                                                    â”‚       â”‚
â”‚  â”‚  â€¢ Cosine Similarity Computation                  â”‚       â”‚
â”‚  â”‚  â€¢ Citation Ranking                               â”‚       â”‚
â”‚  â”‚  â€¢ Novelty Score Calculation                      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  â€¢ Summary                                        â”‚       â”‚
â”‚  â”‚  â€¢ Keywords                                       â”‚       â”‚
â”‚  â”‚  â€¢ Ranked Prior Art Citations                    â”‚       â”‚
â”‚  â”‚  â€¢ Novelty Score & Assessment                    â”‚       â”‚
â”‚  â”‚  â€¢ JSON Report                                    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Module Interaction Diagram

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   pipeline.py   â”‚
                    â”‚  (Orchestrator) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ pdf_extractor   â”‚  â”‚preprocessingâ”‚  â”‚ summarization    â”‚
â”‚      .py        â”‚  â”‚    .py      â”‚  â”‚      .py         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   keyword_      â”‚  â”‚ similarity_ â”‚  â”‚  User Interface  â”‚
â”‚  extraction.py  â”‚  â”‚ ranking.py  â”‚  â”‚ (web/notebook)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

```
1. INPUT
   â”œâ”€â†’ Raw Text / PDF File
   â””â”€â†’ Prior Art Documents

2. EXTRACTION & PREPROCESSING
   â”œâ”€â†’ Extract text from PDF
   â”œâ”€â†’ Clean and normalize
   â””â”€â†’ Remove noise

3. ANALYSIS
   â”œâ”€â†’ Generate summary (TextRank)
   â”œâ”€â†’ Extract keywords (YAKE/RAKE/KeyBERT)
   â””â”€â†’ Prepare for comparison

4. COMPARISON
   â”œâ”€â†’ Convert to vectors (TF-IDF/BERT)
   â”œâ”€â†’ Compute similarity scores
   â””â”€â†’ Rank prior art by relevance

5. ASSESSMENT
   â”œâ”€â†’ Calculate novelty score
   â”œâ”€â†’ Identify most similar prior art
   â””â”€â†’ Generate recommendations

6. OUTPUT
   â”œâ”€â†’ Formatted report
   â”œâ”€â†’ JSON file with all results
   â””â”€â†’ Visualization (optional)
```

## Technology Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Python 3.8+                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NLP Core   â”‚  â”‚  ML/Similarityâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ spaCy     â”‚  â”‚ â€¢ scikit-learnâ”‚
â”‚  â€¢ NLTK      â”‚  â”‚ â€¢ gensim      â”‚
â”‚  â€¢ Gensim    â”‚  â”‚ â€¢ sentence-   â”‚
â”‚              â”‚  â”‚   transformersâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
    â”‚  â”‚  Keyword       â”‚â”‚
    â”‚  â”‚  Extraction    â”‚â”‚
    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
    â”‚  â”‚ â€¢ YAKE         â”‚â”‚
    â”‚  â”‚ â€¢ RAKE         â”‚â”‚
    â”‚  â”‚ â€¢ KeyBERT      â”‚â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
    â”‚                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Data Processing   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ pandas          â”‚
    â”‚  â€¢ numpy           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PDF Processing    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ PyPDF2          â”‚
    â”‚  â€¢ pdfplumber      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Web Interface     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ Flask           â”‚
    â”‚  â€¢ HTML/CSS/JS     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Algorithm Selection Guide

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             KEYWORD EXTRACTION                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  Fast & Simple     â†’  RAKE                           â”‚
â”‚  Best Balance      â†’  YAKE  â­ RECOMMENDED           â”‚
â”‚  Most Accurate     â†’  KeyBERT                        â”‚
â”‚  All Combined      â†’  extract_combined()             â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           SIMILARITY COMPUTATION                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  Fast              â†’  TF-IDF                         â”‚
â”‚  Most Accurate     â†’  BERT                           â”‚
â”‚  Best Overall      â†’  Hybrid  â­ RECOMMENDED         â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SUMMARIZATION                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  For Long Text     â†’  TextRank (sumy)                â”‚
â”‚  For Short Text    â†’  Simple Extraction              â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Performance Characteristics

| Component | Speed | Accuracy | Resource Use |
|-----------|-------|----------|--------------|
| RAKE | âš¡âš¡âš¡ | â­â­ | ğŸ’¾ Low |
| YAKE | âš¡âš¡ | â­â­â­ | ğŸ’¾ Low |
| KeyBERT | âš¡ | â­â­â­â­ | ğŸ’¾ğŸ’¾ Medium |
| TF-IDF | âš¡âš¡âš¡ | â­â­â­ | ğŸ’¾ Low |
| BERT | âš¡ | â­â­â­â­â­ | ğŸ’¾ğŸ’¾ğŸ’¾ High |
| Hybrid | âš¡âš¡ | â­â­â­â­ | ğŸ’¾ğŸ’¾ Medium |

Legend:
- âš¡ = Speed (more = faster)
- â­ = Accuracy (more = better)
- ğŸ’¾ = Resource usage (more = higher)